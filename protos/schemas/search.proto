/**
 This is generated from the spec. DO NOT manually modify.
*/

syntax = "proto3";
package org.opensearch.protobufs;

option java_multiple_files = true;
option java_package = "org.opensearch.protobufs";
option java_outer_classname = "SearchProto";
option go_package = "github.com/opensearch-project/opensearch-protobufs/go/opensearchpb";

import "google/protobuf/struct.proto";
import "protos/schemas/common.proto";


// The Search API operation to perform a search across all indices in the cluster.
// The Search API operation to perform a search or index search
message SearchRequest {
  // [optional] A list of indices to search for documents. If not provided, the default value will be to search through all indexes.
  repeated string index = 1;
  // [optional] Whether to include the _source field in the response.
  optional SourceConfigParam x_source = 2;
  // [optional] A list of source fields to exclude from the response. You can also use this parameter to exclude fields from the subset specified in `source_includes` query parameter. If the `source` parameter is `false`, this parameter is ignored.
  repeated string x_source_excludes = 3;
  // [optional] A list of source fields to include in the response. If this parameter is specified, only these source fields are returned. You can exclude fields from this subset using the `source_excludes` query parameter. If the `source` parameter is `false`, this parameter is ignored.
  repeated string x_source_includes = 4;
  // [optional] Whether to ignore wildcards that don't match any indexes. Default is true.
  optional bool allow_no_indices = 5;
  // [optional] Whether to return partial results if the request runs into an error or times out. Default is true.
  optional bool allow_partial_search_results = 6;
  // [optional] Whether the update operation should include wildcard and prefix queries in the analysis. Default is false.
  optional bool analyze_wildcard = 7;
  // [optional] How many shard results to reduce on a node. Default is 512.
  optional int32 batched_reduce_size = 8;
  // [optional] The time after which the search request will be canceled. Request-level parameter takes precedence over cancel_after_time_interval cluster setting. Default is -1.
  optional string cancel_after_time_interval = 9;
  // [optional] Whether to minimize round-trips between a node and remote clusters. Default is true.
  optional bool ccs_minimize_roundtrips = 10;
  // [optional] Indicates whether the default operator for a string query should be AND or OR. Default is OR.
  optional Operator default_operator = 11;
  // [optional] The default field in case a field prefix is not provided in the query string.
  optional string df = 12;
  // [optional] The fields that OpenSearch should return using their docvalue forms.
  repeated string docvalue_fields = 13;
  // [optional] Specifies the type of index that wildcard expressions can match. Supports list of values. Default is open.
  repeated ExpandWildcard expand_wildcards = 14;
  // [optional] Whether to ignore concrete, expanded, or indexes with aliases if indexes are frozen. Default is true.
  optional bool ignore_throttled = 15;
  // [optional] Specifies whether to include missing or closed indexes in the response and ignores unavailable shards during the search request. Default is false.
  optional bool ignore_unavailable = 16;
  // [optional] Numbers of concurrent shard requests this request should execute on each node. Default is 5.
  optional int32 max_concurrent_shard_requests = 17;
  // [optional] Whether to return phase-level took time values in the response. Default is false.
  optional bool phase_took = 18;
  // [optional] A prefilter size threshold that triggers a prefilter operation if the request exceeds the threshold. Default is 128 shards.
  optional int32 pre_filter_shard_size = 19;
  // [optional] Specifies the shards or nodes on which OpenSearch should perform the search. For valid values see "https://opensearch.org/docs/latest/api-reference/search/#the-preference-query-parameter"
  optional string preference = 20;
  // [optional] Query in the Lucene query string syntax using query parameter search.
  optional string q = 21;
  // [optional] Specifies whether OpenSearch should use the request cache. Default is whether it's enabled in the index's settings.
  optional bool request_cache = 22;
  // [optional] Indicates whether to return hits.total as an integer. Returns an object otherwise. Default is false.
  optional bool total_hits_as_int = 23;
  // [optional] Value used to route the update by query operation to a specific shard.
  repeated string routing = 24;
  // [optional] Period to keep the search context open.
  optional string scroll = 25;
  // [optional] Whether OpenSearch should use global term and document frequencies when calculating relevance scores. Default is SEARCH_TYPE_QUERY_THEN_FETCH.
  // TODO remove these fields from spec?
  // do not allow 'query_and_fetch' or 'dfs_query_and_fetch' search types
  // from the REST layer. these modes are an internal optimization and should
  // not be specified explicitly by the user.
  optional SearchType search_type = 26;
  // [optional] Fields OpenSearch can use to look for similar terms.
  optional string suggest_field = 27;
  // [optional] The mode to use when searching. This parameter can only be used when the `suggest_field` and `suggest_text` query string parameters are specified.
  optional SuggestMode suggest_mode = 28;
  // [optional] Number of suggestions to return.
  optional int32 suggest_size = 29;
  // [optional] The source that suggestions should be based off of.
  optional string suggest_text = 30;
  // [optional] Whether returned aggregations and suggested terms should include their types in the response. Default is true.
  optional bool typed_keys = 31;
  // [optional] Search Request body
  optional SearchRequestBody search_request_body = 32;
  // [optional] Global parameters
  // TODO not supported in server
  optional GlobalParams global_params = 33;
}

message SearchRequestBody {
  // [optional] In the optional aggs parameter, you can define any number of aggregations. Each aggregation is defined by its name and one of the types of aggregations that OpenSearch supports.
  map<string, AggregationContainer> aggregations = 1;

  // [optional] The collapse parameter groups search results by a particular field value. This returns only the top document within each group, which helps reduce redundancy by eliminating duplicates.
  optional FieldCollapse collapse = 2;

  // [optional] Whether to return details about how OpenSearch computed the document's score. Default is false.
  optional bool explain = 3;

  // [optional] ext object is to contain plugin-specific response fields. For example, in conversational search, the result of Retrieval Augmented Generation (RAG) is a single “hit” (answer). Plugin authors can include this answer in the search response as part of the ext object so that it is separate from the search hits.
  optional ObjectMap ext = 4;

  // [optional] The starting index to search from. Default is 0.
  optional int32 from = 5;

  // [optional] Highlighting emphasizes the search term(s) in the results so you can emphasize the query matches.
  optional Highlight highlight = 6;

  // [optional] Whether to return how many documents matched the query.
  optional TrackHits track_total_hits = 7;

  // [optional] Values used to boost the score of specified indexes. Specify in the format of <index> : <boost-multiplier>
  map<string, float> indices_boost = 8;

  // [optional] The fields that OpenSearch should return using their docvalue forms. Specify a format to return results in a certain format, such as date and time.
  repeated FieldAndFormat docvalue_fields = 9;

  // TODO not supported yet
  // RankContainer rank = 10;

  // [optional] Specify a score threshold to return only documents above the threshold.
  optional float min_score = 11;

  // [optional] Use post_filter to refine search hits based on user selections while preserving all aggregation options.
  optional QueryContainer post_filter = 12;

  // [optional] Profile provides timing information about the execution of individual components of a search request. Using the Profile API, you can debug slow requests and understand how to improve their performance.
  optional bool profile = 13;

  // [optional] Customizable sequence of processing stages applied to search queries.
  // TODO add to spec
  optional string search_pipeline = 14;

  // [optional] Enables or disables verbose mode for the search pipeline.
  // TODO add to spec
  optional bool verbose_pipeline = 15;

  // [optional] The DSL query to use in the request.
  optional QueryContainer query = 16;

  // [optional] Can be used to improve precision by reordering just the top (for example 100 - 500) documents returned by the `query` and `post_filter` phases.
  repeated Rescore rescore = 17;

  // [optional] The script_fields parameter allows you to include custom fields whose values are computed using scripts in your search results. This can be useful for calculating values dynamically based on the document data. You can also retrieve derived fields by using a similar approach.
  map<string, ScriptField> script_fields = 18;

  // [optional] The search_after parameter provides a live cursor that uses the previous page's results to obtain the next page's results. It is similar to the scroll operation in that it is meant to scroll many queries in parallel. You can use search_after only when sorting is applied.
  repeated FieldValue search_after = 19;

  // [optional] The number of results to return. Default is 10.
  optional int32 size = 20;

  // [optional] You can use the scroll operation to retrieve a large number of results. For example, for machine learning jobs, you can request an unlimited number of results in batches.
  optional SlicedScroll slice = 21;

  // [optional] Sorting allows your users to sort results in a way that's most meaningful to them. By default, full-text queries sort results by the relevance score. You can choose to sort the results by any field value in either ascending or descending order by setting the order parameter to asc or desc.
  repeated SortCombinations sort = 22;

  // [optional] Whether to include the _source field in the response.
  optional SourceConfig x_source = 23;

  // [optional] The fields to search for in the request. Specify a format to return results in a certain format, such as date and time.
  repeated FieldAndFormat fields = 24;

  // [optional] The suggest feature suggests similar looking terms based on a provided text by using a suggester. The suggest request part is defined alongside the query part in a _search request. If the query part is left out, only suggestions are returned.
  optional Suggester suggest = 25;

  // [optional] The maximum number of documents OpenSearch should process before terminating the request. If a query reaches this limit, OpenSearch terminates the query early. OpenSearch collects documents before sorting. Use with caution. OpenSearch applies this parameter to each shard handling the request. When possible, let OpenSearch perform early termination automatically. Avoid specifying this parameter for requests that target data streams with backing indices across multiple data tiers. If set to `0` (default), the query does not terminate early. Default is 0.
  optional int32 terminate_after = 26;

  // [optional] The period of time to wait for a response. Default is no timeout. If no response is received before the timeout expires, the request fails and returns an error. Defaults to no timeout.
  optional string timeout = 27;

  // [optional] Whether to return document scores. Default is false.
  optional bool track_scores = 28;

  // [optional] Whether to return scores with named queries. Default is false.
  // TODO add to spec
  optional bool include_named_queries_score = 29;

  // [optional] Whether to include the document version in the response.
  optional bool version = 30;

  // [optional] Whether to return sequence number and primary term of the last operation of each document hit.
  optional bool seq_no_primary_term = 31;

  // [optional] A list of stored fields to return as part of a hit. If no fields are specified, no stored fields are included in the response. If this option is specified, the _source parameter defaults to false. You can pass _source: true to return both source fields and stored fields in the search response.
  repeated string stored_fields = 32;

  // [optional] Point in Time (PIT) lets you run different queries against a dataset that is fixed in time.
  optional PointInTimeReference pit = 33;

  // [optional] Value to associate with the request for additional logging.
  repeated string stats = 34;

  // [optional]
  // TODO add to spec (since 2.14)
  map<string, DerivedField> derived = 35;
}

message DerivedField {
  // [required]
  string name = 1;
  // [required]
  string type = 2;
  // [required]
  Script script = 3;
  // [optional]
  optional string prefilter_field = 4;
  // [optional]
  optional ObjectMap properties = 5;
  // [optional]
  optional bool ignore_malformed = 6;
  // [optional]
  optional string format = 7;
}

message TrackHits {
  oneof track_hits {
    bool enabled = 1;

    int32 count = 2;
  }
}

// The response from search request.
message SearchResponse {

  // [required] Milliseconds it took Elasticsearch to execute the request.
  int64 took = 1;

  // [required]  If true, the request timed out before completion; returned results may be partial or empty.
  bool timed_out = 2;

  // [required] Contains a count of shards used for the request.
  ShardStatistics x_shards = 3;

  // [optional] Phase-level took time values in the response.
  optional PhaseTook phase_took = 4;

  // [required] Contains returned documents and metadata.
  HitsMetadata hits = 5;

  // [optional]
  repeated ProcessorExecutionDetail processor_results = 6;

  // [optional] When you search one or more remote clusters, a `_clusters` section is included to provide information about the search on each cluster.
  optional ClusterStatistics x_clusters = 7;

  // [optional] Retrieved specific fields in the search response
  optional ObjectMap fields = 8;

  // [optional] The number of times that the coordinating node aggregates results from batches of shard responses
  optional int32 num_reduce_phases = 9;

  // [optional] Contains profiling information.
  optional Profile profile = 10;

  // [optional] The PIT ID.
  optional string pit_id = 11;

  // [optional] Identifier for the search and its search context.
  optional string x_scroll_id = 12;

  // [optional] If the query was terminated early, the terminated_early flag will be set to true in the response
  optional bool terminated_early = 13;
  // [optional]
  // todo: not supported yet
  // map<string, SuggestArray> suggest = 14;

  // [optional] Aggregation results
  map<string, Aggregate> aggregations = 15;
}

message ProcessorExecutionDetail {
  // [optional]
  optional string processor_name = 1;
  // [optional]
  optional int64 duration_millis = 2;
  // [optional]
  optional ObjectMap input_data = 3;
  // [optional]
  optional ObjectMap output_data = 4;
  // [optional]
  optional string status = 5;
  // [optional]
  optional string tag = 6;
  // [optional]
  optional string error = 7;
}

message PhaseTook {

  // [required] Time taken in dfs_pre_query phase.
  int64 dfs_pre_query = 1;
  // [required] Time taken in query phase.
  int64 query = 2;
  // [required] Time taken in fetch phase.
  int64 fetch = 3;
  // [required] Time taken in dfs_query phase.
  int64 dfs_query = 4;
  // [required] Time taken in expand phase.
  int64 expand = 5;
  // [required] Time taken in can_match phase.
  int64 can_match = 6;

}

message HitsMetadataTotal {
  oneof hits_metadata_total{
    TotalHits total_hits = 1;
    int64 int64 = 2;
  }
}

message HitsMetadataMaxScore{
  oneof hits_metadata_max_score{
    float float = 1;
    NullValue null_value = 2;
  }
}

message HitsMetadata {
  // [optional] Metadata about the number of matching documents.
  optional HitsMetadataTotal total = 1;

  // [required] Array of returned document objects.
  repeated HitsMetadataHitsInner hits = 2;

  // [optional] Highest returned document _score.
  optional HitsMetadataMaxScore max_score = 3;
}

enum TotalHitsRelation {
  TOTAL_HITS_RELATION_UNSPECIFIED = 0;
  TOTAL_HITS_RELATION_EQ = 1;
  TOTAL_HITS_RELATION_GTE = 2;
}

message TotalHits {

  // [required] Indicates whether the number of matching documents in the value parameter is accurate or a lower bound.
  TotalHitsRelation relation = 1;
  // [required] Total number of matching documents.
  int64 value = 2;

}

message InnerHitsResult {

  // [required] An additional nested hits value.
  HitsMetadata hits = 1;

}

message HitXScore {
  oneof hit_x_score {
    NullValue null_value = 1;
    double double = 2;
  }
}

// Content type of the source document
enum SourceContentType {
  SOURCE_CONTENT_TYPE_UNSPECIFIED = 0;
  SOURCE_CONTENT_TYPE_JSON = 1;
  SOURCE_CONTENT_TYPE_SMILE = 2;
  SOURCE_CONTENT_TYPE_CBOR = 3;
  SOURCE_CONTENT_TYPE_YAML = 4;
}

message HitsMetadataHitsInner {

  optional string x_type = 1;

  // [optional] Name of the index containing the returned document.
  optional string x_index = 2;
  // [optional] Unique identifier for the returned document. This ID is only unique within the returned index.
  optional string x_id = 3;

  // [optional] Relevance of the returned document.
  optional HitXScore x_score = 4;

  // [optional] Explanation of how the relevance score (_score) is calculated for every result.
  optional Explanation x_explanation = 5;

  // [optional] Contains field values for the documents.
  optional ObjectMap fields = 6;

  // [optional] An additional highlight element for each search hit that includes the highlighted fields and the highlighted fragments.
  map<string, StringArray> highlight = 7;

  // [optional] An additional nested hits that caused a search hit to match in a different scope.
  map<string, InnerHitsResult> inner_hits = 8;

  // [optional] List of matched query names used in the search request.
  repeated string matched_queries = 9;

  // [optional] Defines from what inner nested object this inner hit came from
  optional NestedIdentity x_nested = 10;

  // [optional] List of fields ignored.
  repeated string x_ignored = 11;

  // [optional] These values are retrieved from the document’s original JSON source and are raw so will not be formatted or treated in any way, unlike the successfully indexed fields which are returned in the fields section.
  map<string, StringArray> ignored_field_values = 12;

  // [optional] Shard from which this document was retrieved.
  optional string x_shard = 13;

  // [optional] Node from which this document was retrieved.
  optional string x_node = 14;

  optional string x_routing = 15;

  // [optional] Source document.
  optional bytes x_source = 16;

  // [optional] Counts the number of operations that happened on the index
  optional int64 x_seq_no = 17;

  // [optional] Counts the number of shard has changed.
  optional int64 x_primary_term = 18;

  // [optional] Version number of the document.
  optional int64 x_version = 19;

  // [optional] Sorted values
  repeated FieldValue sort = 20;

  // [optional] Contains metadata values for the documents.
  // TODO: No field named "meta_fields" in the spec. Needs adaptor_unnest.
  optional ObjectMap meta_fields = 21;

  // [optional] Content type of the x_source document
  optional SourceContentType x_source_content_type = 22;
}

message ClusterStatistics {

  // [required] Number of shards that skipped the request because a lightweight check helped realize that no documents could possibly match on this shard. This typically happens when a search request includes a range filter and the shard only has values that fall outside of that range.
  int32 skipped = 1;

  // [required] Number of shards that executed the request successfully.
  int32 successful = 2;

  // [required] Total number of shards that require querying, including unallocated shards.
  int32 total = 3;


  // TODO these fields dont exist in SearchResponse.Clusters class
  // [required] Number of shards currently executing the search operation
//  int32 running = 4;
//
//  // [required] The number of shards that returned partial results.
//  int32 partial = 5;
//
//  // [required] Number of shards that failed to execute the request. Note that shards that are not allocated will be considered neither successful nor failed. Having failed+successful less than total is thus an indication that some of the shards were not allocated.
//  int32 failed = 6;
//
//  // [optional] Shows metadata about the search on each cluster.
//  map<string, ClusterDetails> details = 7;

}

enum ClusterSearchStatus {
  CLUSTER_SEARCH_STATUS_UNSPECIFIED = 0;
  // The search failed on a cluster marked with skip_unavailable=false
  CLUSTER_SEARCH_STATUS_FAILED = 1;
  // Searches on at least one shard of the cluster was successful and at least one failed
  CLUSTER_SEARCH_STATUS_PARTIAL = 2;
  // Searches on all shards were successful
  CLUSTER_SEARCH_STATUS_RUNNING = 3;
  // The search failed on a cluster marked with skip_unavailable=true
  CLUSTER_SEARCH_STATUS_SKIPPED = 4;
  // Searches on all shards were successful
  CLUSTER_SEARCH_STATUS_SUCCESSFUL = 5;
}

message ClusterDetails {
  // [required] All possible cluster search states.
  ClusterSearchStatus status = 1;

  // [required] The index expression supplied by the user. If you provide a wildcard such as logs-*, this section will show the value with the wildcard, not the concrete indices being searched.
  string indices = 2;

  // [optional] How long (in milliseconds) the sub-search took on that cluster.
  optional int64 took = 3;

  // [required] If true, the request timed out before completion; returned results may be partial or empty.
  bool timed_out = 4;

  // [optional] The shard details for the sub-search on that cluster.
  optional ShardStatistics shards = 5;

  // [optional] An array of any shard-specific failures that occurred during the search operation
  repeated ShardSearchFailure failures = 6;

}

message Profile {

  // [required] A search request can be executed against one or more shards in the index, and a search may involve one or more indexes. Thus, the profile.shards array contains profiling information for each shard that was involved in the search.
  repeated ShardProfile shards = 1;

}

message RescoreQuery {

  // [required] A second query only on the Top-K results returned by the query and post_filter phases.
  QueryContainer rescore_query = 1;

  // [optional] The relative importance of the original query as compared to the rescore query.
  optional float query_weight = 2;

  // [optional] The relative importance of the rescore query as compared to the original query.
  optional float rescore_query_weight = 3;

  // [optional] Control the way the scores are combined.
  optional ScoreMode score_mode = 4;

}

enum ScoreMode {
  SCORE_MODE_UNSPECIFIED = 0;
  SCORE_MODE_AVG = 1;
  SCORE_MODE_MAX = 2;
  SCORE_MODE_MIN = 3;
  SCORE_MODE_MULTIPLY = 4;
  SCORE_MODE_TOTAL = 5;
}

message Rescore {

  // [required] Contains the rescore_query, which is the secondary query used to adjust the scores of the initial results
  RescoreQuery query = 1;

  // [optional] The number of docs which will be examined on each shard can be controlled.
  optional int32 window_size = 2;

}

message SlicedScroll {

  // [optional] Specific document field by which slicing is performed.
  optional string field = 1;

  // [required] The id of the slice
  int32 id = 2;

  // [required] The maximum number of slices
  int32 max = 3;

}

message Suggester {

  // [optional] Global suggest text, to avoid repetition when the same text is used in several suggesters
  optional string text = 1;

}

message ShardProfile {

  // [required] Profiling information about the aggregation execution.
  repeated AggregationProfile aggregations = 1;

  // [required] The shard ID of the shard in the [node-ID][index-name][shard-ID] format.
  string id = 2;

  // [required] Search represents a query executed against the underlying Lucene index. Most search requests execute a single search against a Lucene index, but some search requests can execute more than one search. For example, including a global aggregation results in a secondary match_all query for the global context. The profile.shards array contains profiling information about each search execution.
  repeated SearchProfile searches = 3;

  // [optional] Fetch timing and debug information.
  optional FetchProfile fetch = 4;

}

message AggregationProfile {

  // [required]
  AggregationBreakdown breakdown = 1;
  // [required]
  string description = 2;

  // [required] Time unit for nanoseconds
  int64 time_in_nanos = 3;
  // [required]
  string type = 4;

  // [optional]
  optional AggregationProfileDebug debug = 5;
  // [optional]
  repeated AggregationProfile children = 6;

}

message AggregationBreakdown {

  // [required] Contains the time spent running the aggregation’s buildAggregations() method, which builds the results of this aggregation. For concurrent segment search, the build_aggregation method contains the total elapsed time across all slices (the difference between the last completed slice execution end time and the first slice execution start time).
  int64 build_aggregation = 1;

  // [required] Contains the number of invocations of a build_aggregation.
  int64 build_aggregation_count = 2;

  // [required] Contains the time spent running the aggregation’s getLeafCollector() method, which creates a new collector to collect the given context. For concurrent segment search, the build_leaf_collector method contains the total elapsed time across all slices (the difference between the last completed slice execution end time and the first slice execution start time).
  int64 build_leaf_collector = 3;

  // [required] Contains the number of invocations of a build_leaf_collector.
  int64 build_leaf_collector_count = 4;

  // [required] Contains the time spent collecting the documents into buckets. For concurrent segment search, the collect method contains the total elapsed time across all slices (the difference between the last completed slice execution end time and the first slice execution start time).
  int64 collect = 5;

  // [required] Contains the number of invocations of a collect.
  int64 collect_count = 6;

  // [required] Contains the amount of time taken to execute the preCollection() callback method during AggregationCollectorManager creation. For concurrent segment search, the initialize method contains the total elapsed time across all slices (the difference between the last completed slice execution end time and the first slice execution start time).
  int64 initialize = 7;

  // [required] Contains the number of invocations of a initialize.
  int64 initialize_count = 8;

  // [optional] Contains the time spent running the aggregation’s postCollection() callback method. For concurrent segment search, the post_collection method contains the total elapsed time across all slices (the difference between the last completed slice execution end time and the first slice execution start time).
  optional int64 post_collection = 9;

  // [optional] Contains the number of invocations of a post_collection.
  optional int64 post_collection_count = 10;

  // [required] Contains the time spent in the reduce phase. For concurrent segment search, the reduce method contains the total elapsed time across all slices (the difference between the last completed slice execution end time and the first slice execution start time).
  int64 reduce = 11;

  // [required] Contains the number of invocations of a reduce.
  int64 reduce_count = 12;

}

message SearchProfile {

  // [required] Profiling information about the Lucene collectors that ran the search.
  repeated Collector collector = 1;

  // [required] Profiling information about the query execution.
  repeated QueryProfile query = 2;

  // [required] All Lucene queries are rewritten. A query and its children may be rewritten more than once, until the query stops changing. The rewriting process involves performing optimizations, such as removing redundant clauses or replacing a query path with a more efficient one. After the rewriting process, the original query may change significantly. The rewrite_time field contains the cumulative total rewrite time for the query and all its children, in nanoseconds.
  int64 rewrite_time = 3;

}

message NumberMap {
  map<string, float> number_map = 1;
}


message PointInTimeReference {
  // [required] ID for the PIT to search. If you provide a pit object, this parameter is required.
  string id = 1;

  // [optional] Period of time used to extend the life of the PIT. Units can be `nanos`, `micros`, `ms` (milliseconds), `s` (seconds), `m` (minutes), `h` (hours) and `d` (days). Also accepts \"0\" without a unit and \"-1\" to indicate an unspecified value.
  optional string keep_alive = 2;

}

message Collector {

  // [required] The collector name.
  string name = 1;

  // [required] Contains a description of the collector.
  string reason = 2;

  // [required] The total elapsed time for this collector, in nanoseconds. For concurrent segment search, time_in_nanos is the total amount of time across all slices (the difference between the last completed slice execution end time and the first slice execution start time).
  int64 time_in_nanos = 3;

  // [optional] If a collector has subcollectors (children), this field contains information about the subcollectors.
  repeated Collector children = 4;

}

message QueryProfile {

  // [required] Contains timing statistics about low-level Lucene execution.
  QueryBreakdown breakdown = 1;

  // [required] Contains a Lucene explanation of the query. Helps differentiate queries with the same type.
  string description = 2;

  // [required] The total elapsed time for this query, in nanoseconds. For concurrent segment search, time_in_nanos is the total time spent across all the slices (the difference between the last completed slice execution end time and the first slice execution start time).
  int64 time_in_nanos = 3;

  // [required] The Lucene query type into which the search query was rewritten. Corresponds to the Lucene class name (which often has the same name in OpenSearch).
  string type = 4;

  // [optional] If a query has subqueries (children), this field contains information about the subqueries.
  repeated QueryProfile children = 5;

}

message QueryBreakdown {

  // [required] The advance method is a lower-level version of the next_doc method in Lucene. It also finds the next matching document but necessitates that the calling query perform additional tasks, such as identifying skips. Some queries, such as conjunctions (must clauses in Boolean queries), cannot use next_doc. For those queries, advance is timed.
  int64 advance = 1;
  // [required] Contains the number of invocations of the advance method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 advance_count = 2;
  // [required] A Scorer iterates over matching documents and generates a score for each document. The build_scorer field contains the amount of time spent generating the Scorer object. This does not include the time spent scoring the documents. The Scorer initialization time depends on the optimization and complexity of a particular query. The build_scorer parameter also includes the amount of time associated with caching, if caching is applicable and enabled for the query.
  int64 build_scorer = 3;
  // [required] Build_scorer_count contains the number of invocations of the build_scorer method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 build_scorer_count = 4;
  // [required] A Query object in Lucene is immutable. Yet, Lucene should be able to reuse Query objects in multiple IndexSearcher objects. Thus, Query objects need to keep temporary state and statistics associated with the index in which the query is executed. To achieve reuse, every Query object generates a Weight object, which keeps the temporary context (state) associated with the <IndexSearcher, Query> tuple. The create_weight field contains the amount of time spent creating the Weight object.
  int64 create_weight = 5;
  // [required] Create_weight_count contains the number of invocations of the create_weight method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 create_weight_count = 6;
  // [required] For some queries, document matching is performed in two steps. First, the document is matched approximately. Second, those documents that are approximately matched are examined through a more comprehensive process. For example, a phrase query first checks whether a document contains all terms in the phrase. Next, it verifies that the terms are in order (which is a more expensive process). The match field is non-zero only for those queries that use the two-step verification process.
  int64 match = 7;
  // [required] Match_count contains the number of invocations of the match method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 match_count = 8;
  // [required] Contains the amount of time required to execute the advanceShallow Lucene method.
  int64 shallow_advance = 9;
  // [required] Shallow_advance_count contains the number of invocations of the shallow_advance method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 shallow_advance_count = 10;
  // [required] The next_doc Lucene method returns the document ID of the next document that matches the query. This method is a special type of the advance method and is equivalent to advance(docId() + 1). The next_doc method is more convenient for many Lucene queries. The next_doc field contains the amount of time required to determine the next matching document, which varies depending on the query type.
  int64 next_doc = 11;
  // [required] Next_doc_count contains the number of invocations of the next_doc method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 next_doc_count = 12;
  // [required] Contains the time taken for a Scorer to score a particular document.
  int64 score = 13;
  // [required] Score_count contains the number of invocations of the score method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 score_count = 14;
  // [required] Contains the amount of time required to execute the getMaxScore Lucene method.
  int64 compute_max_score = 15;
  // [required] Compute_max_score_count contains the number of invocations of the compute_max_score method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 compute_max_score_count = 16;
  // [required] Contains the amount of time required to execute the setMinCompetitiveScore Lucene method.
  int64 set_min_competitive_score = 17;
  // [required] Set_min_competitive_score_count contains the number of invocations of the set_min_competitive_score method. Different invocations of the same method occur because the method is called on different documents. You can determine the selectivity of a query by comparing counts in different query components.
  int64 set_min_competitive_score_count = 18;

}

message FetchProfileDebug {

  repeated string stored_fields = 1;

  optional int32 fast_path = 2;

}

message FetchProfile {

  string type = 1;

  string description = 2;

  // Time unit for nanoseconds
  int64 time_in_nanos = 3;

  FetchProfileBreakdown breakdown = 4;

  optional FetchProfileDebug debug = 5;

  repeated FetchProfile children = 6;

}


message FetchProfileBreakdown {
  optional int32 load_source = 1;

  optional int32 load_source_count = 2;

  optional int32 load_stored_fields = 3;

  optional int32 load_stored_fields_count = 4;

  optional int32 next_reader = 5;

  optional int32 next_reader_count = 6;

  optional int32 process_count = 7;

  optional int32 process = 8;
}

message AggregationProfileDebug {

  optional int32 segments_with_multi_valued_ords = 1;

  optional string collection_strategy = 2;

  optional int32 segments_with_single_valued_ords = 3;

  optional int32 total_buckets = 4;

  optional int32 built_buckets = 5;

  optional string result_strategy = 6;

  optional bool has_filter = 7;

  optional string delegate = 8;

  optional AggregationProfileDelegateDebug delegate_debug = 9;

  optional int32 chars_fetched = 10;

  optional int32 extract_count = 11;

  optional int32 extract_ns = 12;

  optional int32 values_fetched = 13;

  optional int32 collect_analyzed_ns = 14;

  optional int32 collect_analyzed_count = 15;

  optional int32 surviving_buckets = 16;

  optional int32 ordinals_collectors_used = 17;

  optional int32 ordinals_collectors_overhead_too_high = 18;

  optional int32 string_hashing_collectors_used = 19;

  optional int32 numeric_collectors_used = 20;

  optional int32 empty_collectors_used = 21;

  repeated string deferred_aggregators = 22;

  optional string map_reducer = 28;

}

message AggregationProfileDelegateDebug {
  optional int32 segments_with_doc_count_field = 1;

  optional int32 segments_with_deleted_docs = 2;

  repeated AggregationProfileDelegateDebugFilter filters = 3;

  optional int32 segments_counted = 4;

  optional int32 segments_collected = 5;
}

message AggregationProfileDelegateDebugFilter {

  optional int32 results_from_metadata = 1;

  optional string query = 2;

  optional string specialized_for = 3;

  optional int32 segments_counted_in_constant_time = 4;

}

message Explanation {

  // [required] Explains what type of calculation is performed
  string description = 1;
  // [optional] Shows any subcalculations performed.
  repeated Explanation details = 2;
  // [required] Shows the result of the calculation,
  float value = 3;

}

message NestedIdentity {

  // [required] The name of the nested field.
  string field = 1;

  // [required] Indicates the position or index of the nested document.
  int32 offset = 2;

  // [optional] Inner nested object.
  optional NestedIdentity x_nested = 3;

}

message AggregationContainer {
  // [optional] The custom metadata attached to a resource.
  optional ObjectMap meta = 1;

  oneof aggregation {
    // AdjacencyMatrixAggregation adjacency_matrix = 2;

    // AutoDateHistogramAggregation auto_date_histogram = 3;

    // AverageAggregation avg = 4;

    // AverageBucketAggregation avg_bucket = 5;

    // BoxplotAggregation boxplot = 6;

    // BucketScriptAggregation bucket_script = 7;

    // BucketSelectorAggregation bucket_selector = 8;

    // BucketSortAggregation bucket_sort = 9;

    // [optional] cardinality aggregation
    CardinalityAggregation cardinality = 10;

    // ChildrenAggregation children = 11;

    // CompositeAggregation composite = 12;

    // CumulativeCardinalityAggregation cumulative_cardinality = 13;

    // CumulativeSumAggregation cumulative_sum = 14;

    // DateHistogramAggregation date_histogram = 15;

    // DateRangeAggregation date_range = 16;

    // DerivativeAggregation derivative = 17;

    // DiversifiedSamplerAggregation diversified_sampler = 18;

    // ExtendedStatsAggregation extended_stats = 19;

    // ExtendedStatsBucketAggregation extended_stats_bucket = 20;

    // [optional] filter query which limits matching documents for the aggregations and its sub aggregations
    QueryContainer filter = 21;

    // FiltersAggregation filters = 22;

    // GeoBoundsAggregation geo_bounds = 23;

    // GeoCentroidAggregation geo_centroid = 24;

    // GeoDistanceAggregation geo_distance = 25;

    // GeoHashGridAggregation geohash_grid = 26;

    // GeoTileGridAggregation geotile_grid = 27;

    // GlobalAggregation global = 28;

    // HistogramAggregation histogram = 29;

    // IpRangeAggregation ip_range = 30;

    // MatrixStatsAggregation matrix_stats = 31;

    // MaxAggregation max = 32;

    // MaxBucketAggregation max_bucket = 33;

    // MedianAbsoluteDeviationAggregation median_absolute_deviation = 34;

    // MinAggregation min = 35;

    // MinBucketAggregation min_bucket = 36;

    // [optional] missing aggregation
    MissingAggregation missing = 37;

    // MovingAverageAggregation moving_avg = 38;

    // MovingPercentilesAggregation moving_percentiles = 39;

    // MovingFunctionAggregation moving_fn = 40;

    // MultiTermsAggregation multi_terms = 41;

    // NestedAggregation nested = 42;

    // NormalizeAggregation normalize = 43;

    // ParentAggregation parent = 44;

    // PercentileRanksAggregation percentile_ranks = 45;

    // PercentilesAggregation percentiles = 46;

    // PercentilesBucketAggregation percentiles_bucket = 47;

    // RangeAggregation range = 48;

    // RareTermsAggregation rare_terms = 49;

    // RateAggregation rate = 50;

    // ReverseNestedAggregation reverse_nested = 51;

    // SamplerAggregation sampler = 52;

    // ScriptedMetricAggregation scripted_metric = 53;

    // SerialDifferencingAggregation serial_diff = 54;

    // SignificantTermsAggregation significant_terms = 55;

    // SignificantTextAggregation significant_text = 56;

    // StatsAggregation stats = 57;

    // StatsBucketAggregation stats_bucket = 58;

    // SumAggregation sum = 59;

    // SumBucketAggregation sum_bucket = 60;

    // [optional] terms aggregation
    TermsAggregation terms = 61;

    // TopHitsAggregation top_hits = 62;

    // TTestAggregation t_test = 63;

    // ValueCountAggregation value_count = 64;

    // WeightedAverageAggregation weighted_avg = 65;

    // VariableWidthHistogramAggregation variable_width_histogram = 66;
  }
}

message Aggregate {
  // optional AdjacencyMatrixAggregate adjacency_matrix = 1;

  // optional AutoDateHistogramAggregate auto_date_histogram = 2;

  // optional AvgAggregate avg = 3;

  // optional BoxPlotAggregate box_plot = 4;

  // optional BucketMetricValueAggregate bucket_metric_value = 5;

  // [optional] cardinality aggregation response
  optional CardinalityAggregate cardinality = 6;

  // optional ChildrenAggregate children = 7;

  // optional CompositeAggregate composite = 8;

  // optional DateHistogramAggregate date_histogram = 9;

  // optional DateRangeAggregate date_range = 10;

  // optional DerivativeAggregate derivative = 11;

  // optional DoubleTermsAggregate dterms = 12;

  // optional ExtendedStatsAggregate extended_stats = 13;

  // optional ExtendedStatsBucketAggregate extended_stats_bucket = 14;

  // optional FilterAggregate filter = 15;

  // optional FiltersAggregate filters = 16;

  // optional GeoBoundsAggregate geo_bounds = 17;

  // optional GeoCentroidAggregate geo_centroid = 18;

  // optional GeoDistanceAggregate geo_distance = 19;

  // optional GeoHashGridAggregate geohash_grid = 20;

  // optional GeoTileGridAggregate geotile_grid = 21;

  // optional GlobalAggregate global = 22;

  // optional HdrPercentilesAggregate hdr_percentiles = 23;

  // optional HdrPercentileRanksAggregate hdr_percentile_ranks = 24;

  // optional HistogramAggregate histogram = 25;

  // optional IpRangeAggregate ip_range = 26;

  // optional LongRareTermsAggregate lrareterms = 27;

  // optional LongTermsAggregate lterms = 28;

  // optional MatrixStatsAggregate matrix_stats = 29;

  // optional MaxAggregate max = 30;

  // optional MedianAbsoluteDeviationAggregate median_absolute_deviation = 31;

  // optional MinAggregate min = 32;

  // [optional] cardinality aggregation response
  optional MissingAggregate missing = 33;

  // optional MultiTermsAggregate multi_terms = 34;

  // optional NestedAggregate nested = 35;

  // optional ParentAggregate parent = 36;

  // optional PercentilesBucketAggregate percentiles_bucket = 37;

  // optional RangeAggregate range = 38;

  // optional RateAggregate rate = 39;

  // optional ReverseNestedAggregate reverse_nested = 40;

  // optional SamplerAggregate sampler = 41;

  // optional ScriptedMetricAggregate scripted_metric = 42;

  // optional SignificantLongTermsAggregate siglterms = 43;

  // optional SignificantStringTermsAggregate sigsterms = 44;

  // optional CumulativeCardinalityAggregate simple_long_value = 45;

  // optional SimpleValueAggregate simple_value = 46;

  // optional StatsAggregate stats = 47;

  // optional StatsBucketAggregate stats_bucket = 48;

  // optional StringRareTermsAggregate srareterms = 49;

  // optional StringTermsAggregate sterms = 50;

  // optional SumAggregate sum = 51;

  // optional TDigestPercentilesAggregate tdigest_percentiles = 52;

  // optional TDigestPercentileRanksAggregate tdigest_percentile_ranks = 53;

  // optional TTestAggregate t_test = 54;

  // optional TopHitsAggregate top_hits = 55;

  // optional UnmappedRareTermsAggregate umrareterms = 56;

  // optional UnmappedSignificantTermsAggregate umsigterms = 57;

  // optional UnmappedTermsAggregate umterms = 58;

  // optional ValueCountAggregate value_count = 59;

  // optional VariableWidthHistogramAggregate variable_width_histogram = 60;

  // optional WeightedAvgAggregate weighted_avg = 61;
}

message CardinalityAggregation {
  // [optional] The custom metadata attached to a resource.
  optional ObjectMap meta = 1;

  // [optional] Field for which to calculate cardinality.
  optional string field = 2;

  // [optional] If set documents missing the field are counted towards the cardinality total.
  // Note the FieldValue provided here is arbitrary for the purposes of CardinalityAggregation.
  optional FieldValue missing = 3;

  // [optional] Script to be included in aggregation execution.
  optional Script script = 4;

  // [optional] A unique count below which counts are expected to be close to accurate. This allows to trade memory for accuracy.
  optional int32 precision_threshold = 5;

  // [optional] Execution hint to achieve higher performance given specific conditions. Added in OpenSearch 2.19.1.
  optional CardinalityExecutionMode execution_hint = 6;
}

message CardinalityAggregate {
  // [optional] The custom metadata attached to a resource.
  optional ObjectMap meta = 1;

  // [required] Field cardinality.
  int64 value = 2;
}

enum CardinalityExecutionMode {
  // OpenSearch will determine execution mode automatically when none specified.
  CARDINALITY_EXECUTION_MODE_UNSPECIFIED = 0;
  // Cardinality will be calculated by hashing the contents of each field.
  // Standard approach for high cardinality fields where field contents is not frequently repeated.
  CARDINALITY_EXECUTION_MODE_DIRECT = 1;
  // Cardinality will be calculated based on the global ordinals for this field.
  // More memory efficient for low cardinality fields where global ordinals can be efficiently calculated.
  CARDINALITY_EXECUTION_MODE_GLOBAL_ORDINALS = 2;
  // Save memory by using a segmented approach for HLL structures (added in OpenSearch 2.19.1).
  CARDINALITY_EXECUTION_MODE_SEGMENT_ORDINALS = 3;
}

message MissingAggregation {
  // [optional] The custom metadata attached to a resource.
  optional ObjectMap meta = 1;

  // [optional] Sub-aggregations for this bucket aggregation
  map<string, AggregationContainer> aggregations = 2;

  // [optional] The path to a field or an array of paths. Some APIs support wildcards in the path, which allows you to select multiple fields.
  optional string field = 3;
}

message MissingAggregate {
  // [optional] The custom metadata attached to a resource.
  optional ObjectMap meta = 1;

  // [required] Count of documents missing the field.
  int64 doc_count = 2;

  // [optional] Result of sub aggregations on missing field docs.
  map<string, Aggregate> aggregations = 3;
}

message StringMap {
  map<string, string> string_map = 1;
}

message TermsAggregation {
  // The custom metadata attached to a resource.
  optional ObjectMap meta = 1;

  // Sub-aggregations for this bucket aggregation
  map<string, AggregationContainer> aggregations = 3;

  // Sub-aggregations for this bucket aggregation
  map<string, AggregationContainer> aggs = 4;

  optional TermsAggregationCollectMode collect_mode = 5;

  repeated string exclude = 6;

  optional TermsAggregationExecutionHint execution_hint = 7;

  // The path to a field or an array of paths. Some APIs support wildcards in the path, which allows you to select multiple fields.
  optional string field = 8;

  optional TermsInclude include = 9;

  // Only return values that are found in more than `min_doc_count` hits.
  optional int32 min_doc_count = 10;

  optional FieldValue missing = 11;

  // Coerced unmapped fields into the specified type.
  optional string value_type = 14;

  repeated StringMap order = 15;

  optional Script script = 16;

  // The number of candidate terms produced by each shard. By default, `shard_size` will be automatically estimated based on the number of shards and the `size` parameter.
  optional int32 shard_size = 17;

  // Set to `true` to return the `doc_count_error_upper_bound`, which is an upper bound to the error on the `doc_count` returned by each shard.
  optional bool show_term_doc_count_error = 18;

  // The number of buckets returned out of the overall terms list.
  optional int32 size = 19;

  optional string format = 20;

  // The minimum number of documents in a bucket on each shard for it to be returned.
  optional int32 shard_min_doc_count = 21;
}

enum TermsAggregationCollectMode {
  TERMS_AGGREGATION_COLLECT_MODE_UNSPECIFIED = 0;
  TERMS_AGGREGATION_COLLECT_MODE_BREADTH_FIRST = 1;
  TERMS_AGGREGATION_COLLECT_MODE_DEPTH_FIRST = 2;
}

enum TermsAggregationExecutionHint {
  TERMS_AGGREGATION_EXECUTION_HINT_UNSPECIFIED = 0;
  TERMS_AGGREGATION_EXECUTION_HINT_GLOBAL_ORDINALS = 1;
  TERMS_AGGREGATION_EXECUTION_HINT_GLOBAL_ORDINALS_HASH = 2;
  TERMS_AGGREGATION_EXECUTION_HINT_GLOBAL_ORDINALS_LOW_CARDINALITY = 3;
  TERMS_AGGREGATION_EXECUTION_HINT_MAP = 4;
}

message TermsInclude {
  oneof terms_include {
    StringArray string_array = 1;

    TermsPartition partition = 2;
  }
}

message TermsPartition {
  // The number of partitions.
  int64 num_partitions = 1;

  // The partition number for this request.
  int64 partition = 2;
}
